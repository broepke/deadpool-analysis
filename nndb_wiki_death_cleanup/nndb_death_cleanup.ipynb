{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spacy English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove specified phrases from a string\n",
    "def remove_phrases(text, phrases_to_remove):\n",
    "    for phrase in phrases_to_remove:\n",
    "        text = text.replace(phrase, '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process text with Spacy, remove stop words and unwanted phrases\n",
    "def spacy_process(text, phrases_to_remove):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    text = remove_phrases(text, phrases_to_remove)\n",
    "    doc = nlp(text)\n",
    "    return [token.text.lower() for token in doc if not token.is_stop and not token.is_punct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cause_spacy(cause, key_terms, term_mappings):\n",
    "    # First check specific terms in the mappings\n",
    "    for term, category in term_mappings.items():\n",
    "        if term in cause:\n",
    "            return category\n",
    "\n",
    "    # Then check general terms\n",
    "    for term in key_terms:\n",
    "        if term in cause:\n",
    "            return term\n",
    "\n",
    "    return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_categorize_data_spacy(file_path):\n",
    "    # Load the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Standardize No Information Entries and Normalize Text\n",
    "    no_info_terms = [\"not mentioned\", \"no relevant section found\", \"unknown\"]\n",
    "    data['Cause_of_Death'] = data['Cause_of_Death'].str.lower().apply(\n",
    "        lambda x: 'unknown' if isinstance(x, str) and any(term in x for term in no_info_terms) else x)\n",
    "\n",
    "    # List of phrases to remove\n",
    "    phrases_to_remove = [\"cause of death: \", \"death cause: \", \"complications from \", \"the cause of death was \"]\n",
    "\n",
    "    # Process text and remove unwanted phrases\n",
    "    data['Cause_of_Death'] = data['Cause_of_Death'].apply(lambda x: ' '.join(spacy_process(x, phrases_to_remove)) if isinstance(x, str) else x)\n",
    "\n",
    "    # Key terms and their mappings\n",
    "    key_terms = ['cancer', 'heart', 'stroke', 'accident', 'suicide', 'murder',\n",
    "                 'organ failure', 'pneumonia', 'respiratory', 'natural causes',\n",
    "                 'tumor', 'diabetes', 'pulmonary', 'brain', 'poisoning', \n",
    "                 'liver', 'illness', 'als', 'kidney', 'assassination', 'tuberculosis', 'overdose', 'alzheimer', \n",
    "                 'parkinson', 'drowning', 'covid-19']\n",
    "    \n",
    "    term_mappings = {'injury': 'accident', 'cardiac arrest': 'heart', 'blunt trauma': 'accident', 'leukemia': 'cancer',\n",
    "                     'cardiac':'heart', 'myeloma': 'cancer', 'cerebral': 'brain', 'gunshot': 'murder', 'hanged':'suicide',\n",
    "                     'lymphoma': 'cancer', 'shot':'murder', 'mesothelioma':'cancer', 'stab': 'murder',\n",
    "                     'cirrhosis':'liver', 'crash':'accident', 'collision':'accident', 'dementia':'alzheimer',\n",
    "                     'fall':'accident', 'hanging':'suicide', 'cardiovascular':'heart', 'knife wound':'murder',\n",
    "                     'unspecified': 'unknown', 'emphysema':'respiratory'}\n",
    "\n",
    "    # Categorize the causes of death\n",
    "    data['Categorized_Cause'] = data['Cause_of_Death'].apply(lambda x: categorize_cause_spacy(x, key_terms, term_mappings))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage\n",
    "file_path = 'wiki_died_output.csv'  # Replace with your CSV file path\n",
    "cleaned_data_spacy = clean_and_categorize_data_spacy(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_unknown = cleaned_data_spacy[cleaned_data_spacy['Cause_of_Death'] != 'unknown']\n",
    "filtered_data = filtered_unknown[filtered_unknown['Categorized_Cause'] == 'other']\n",
    "print(filtered_data[['Cause_of_Death', 'Categorized_Cause']].sample(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_unknown['Categorized_Cause'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
